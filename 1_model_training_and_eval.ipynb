{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "394015a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.utils # For gradient clipping\n",
    "import torch.autograd # For anomaly detection\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau, StepLR \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import sys\n",
    "import logging\n",
    "from collections import defaultdict\n",
    "from tqdm.notebook import tqdm # Use notebook version of tqdm (ensure ipywidgets is installed)\n",
    "# from tqdm import tqdm # Alternative if ipywidgets causes issues\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from timeit import default_timer\n",
    "from datetime import datetime\n",
    "import csv\n",
    "\n",
    "\n",
    "from utils.modelIO import load_metadata, load_model, save_model, save_metadata\n",
    "from utils.datasets import get_dataloaders # Use corrected version\n",
    "from utils.helpers import get_n_param, new_model_dir, set_seed, array # Import array helper\n",
    "from models.losses import BCE # Use corrected version\n",
    "from models.models import MODELS, init_model # Use corrected version\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ce3a623c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Configuration ---\n",
    "T_HOURS = 48\n",
    "N_BINS = 20\n",
    "SEED = 0\n",
    "MAX_LEN = 10000 # Max sequence length used during training\n",
    "\n",
    "# Paths\n",
    "PROJECT_ROOT = \"/changed\" # Adjust if needed\n",
    "DATA_ROOT_DIR = os.path.join(PROJECT_ROOT, \"final_data\") # Or your output_dir\n",
    "RESULTS_DIR = os.path.join(PROJECT_ROOT, \"results\")\n",
    "MODEL_RUN_NAME_BASE = \"MortalityLSTM\" # Give a unique name for this run\n",
    "\n",
    "# Hyperparameters\n",
    "LR = 0.0001 \n",
    "EPOCHS = 150 # Number of epochs to run\n",
    "BATCH_SIZE = 128\n",
    "LATENT_DIM = 32\n",
    "HIDDEN_DIM = 256\n",
    "P_DROPOUT = 0.0\n",
    "EARLY_STOPPING_PATIENCE = 5 # Set to large number or None to effectively disable for full run\n",
    "MODEL_TYPE = 'Mortality'\n",
    "DT = 1.0\n",
    "WEIGHTED = False # Set to False to test without weighted embeddings\n",
    "DYNAMIC = True\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8a232422",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-30 13:01:12 [INFO] Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# --- Setup Logging ---\n",
    "logging.basicConfig(level=logging.INFO,\n",
    "                    format='%(asctime)s [%(levelname)s] %(message)s',\n",
    "                    datefmt='%Y-%m-%d %H:%M:%S')\n",
    "logger = logging.getLogger(\"FullRunNotebook\")\n",
    "\n",
    "# --- Enable Anomaly Detection (Optional) ---\n",
    "# torch.autograd.set_detect_anomaly(True)\n",
    "# logger.info(\"PyTorch anomaly detection enabled.\")\n",
    "\n",
    "# --- Redefine LossesLogger (or import from train.py) ---\n",
    "class LossesLogger(object):\n",
    "    \"\"\" Minimal logger for epoch results \"\"\"\n",
    "    def __init__(self, file_path_name):\n",
    "        self.file_path_name = file_path_name\n",
    "        self.header_written = False\n",
    "        # Ensure directory exists\n",
    "        log_dir = os.path.dirname(file_path_name)\n",
    "        if log_dir: os.makedirs(log_dir, exist_ok=True)\n",
    "        # Clear file if exists\n",
    "        if os.path.isfile(file_path_name): os.remove(file_path_name)\n",
    "\n",
    "    def log(self, epoch, storer):\n",
    "        try:\n",
    "            fieldnames = ['Epoch', 'Train_Loss', 'Valid_Loss', 'Valid_AUROC']\n",
    "            # Extract metrics, providing default NaN if key missing or value is None/empty\n",
    "            train_loss = np.nanmean(storer.get('train_loss', [np.nan]))\n",
    "            valid_loss = np.nanmean(storer.get('valid_loss', [np.nan]))\n",
    "            valid_auroc = np.nanmean(storer.get('auroc', [np.nan])) # Assumes 'auroc' key is used\n",
    "\n",
    "            result_data = {\n",
    "                'Epoch': epoch + 1,\n",
    "                'Train_Loss': f\"{train_loss:.4f}\" if np.isfinite(train_loss) else \"nan\",\n",
    "                'Valid_Loss': f\"{valid_loss:.4f}\" if np.isfinite(valid_loss) else \"nan\",\n",
    "                'Valid_AUROC': f\"{valid_auroc:.4f}\" if np.isfinite(valid_auroc) else \"nan\"\n",
    "            }\n",
    "\n",
    "            file_exists = os.path.isfile(self.file_path_name)\n",
    "            with open(self.file_path_name, 'a', newline='', encoding='utf-8') as csvfile:\n",
    "                writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "                if not file_exists or os.path.getsize(self.file_path_name) == 0:\n",
    "                    writer.writeheader()\n",
    "                writer.writerow(result_data)\n",
    "        except Exception as e:\n",
    "             print(f\"Error logging epoch {epoch+1} results: {e}\")\n",
    "\n",
    "\n",
    "set_seed(SEED)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "logger.info(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "903d314b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## 3. Define Paths and Create Directories\n",
    "\n",
    "model_name_suffix = f't{T_HOURS}_lr{LR}_z{LATENT_DIM}' \\\n",
    "                  + f'_h{HIDDEN_DIM}_p{P_DROPOUT}_w{WEIGHTED}_d{DYNAMIC}_seed{SEED}' # Added weighted/dynamic\n",
    "model_run_name = f'{MODEL_RUN_NAME_BASE}_{model_name_suffix}'\n",
    "model_dir = os.path.join(RESULTS_DIR, model_run_name)\n",
    "\n",
    "# Define paths to data files\n",
    "array_dir = os.path.join(DATA_ROOT_DIR, 'arrays')\n",
    "dict_dir = os.path.join(DATA_ROOT_DIR, 'dictionaries')\n",
    "split_dir = os.path.join(DATA_ROOT_DIR, 'splits')\n",
    "\n",
    "array_path = os.path.join(array_dir, f'{T_HOURS}_{SEED}_{N_BINS}-arrays.npz')\n",
    "token_map_path = os.path.join(dict_dir, f'{T_HOURS}_{SEED}_{N_BINS}-token2index.npy')\n",
    "train_split_path = os.path.join(split_dir, f'{SEED}-{T_HOURS}-train.csv')\n",
    "valid_split_path = os.path.join(split_dir, f'{SEED}-{T_HOURS}-valid.csv')\n",
    "test_split_path = os.path.join(split_dir, f'{SEED}-{T_HOURS}-test.csv')\n",
    "\n",
    "# Check files exist\n",
    "required_files = [array_path, token_map_path, train_split_path, valid_split_path, test_split_path]\n",
    "for f_path in required_files:\n",
    "    if not os.path.exists(f_path):\n",
    "        raise FileNotFoundError(f\"Required data file not found: {f_path}\")\n",
    "\n",
    "# Create results directory for this run\n",
    "new_model_dir(model_dir, logger=logger)\n",
    "losses_logger = LossesLogger(os.path.join(model_dir, 'epoch_losses.csv')) # Init logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7b7aebd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-30 13:01:12 [INFO] Loading token map...\n",
      "2025-04-30 13:01:12 [INFO] Vocabulary size (n_tokens): 39727\n",
      "2025-04-30 13:01:12 [INFO] Loading train/validation dataloaders...\n",
      "2025-04-30 13:01:12 [INFO] Loading full dataset arrays from: /changed/final_data/arrays/48_0_20-arrays.npz\n",
      "2025-04-30 13:02:06 [INFO]  Loaded data shapes: X=(24424, 10000, 2), Y=(24424,), Paths=(24424,)\n",
      "2025-04-30 13:02:06 [INFO] Loading token map from: /changed/final_data/dictionaries/48_0_20-token2index.npy\n",
      "2025-04-30 13:02:06 [INFO]  Token map loaded. Vocabulary size (n_tokens): 39727\n",
      "2025-04-30 13:02:06 [INFO] Loaded training set: 9539 samples based on /changed/final_data/splits/0-48-train.csv\n",
      "2025-04-30 13:02:06 [INFO] Loaded validation set: 10000 samples based on /changed/final_data/splits/0-48-valid.csv\n",
      "2025-04-30 13:02:07 [INFO] üîç Initial Token ID range in loaded data: min=0, max=39725\n",
      "2025-04-30 13:02:07 [INFO]   Expected vocabulary size (n_tokens): 39727\n",
      "2025-04-30 13:02:07 [INFO]   Token IDs are within the expected range.\n",
      "2025-04-30 13:02:07 [INFO] üîç Initial Token ID range in loaded data: min=0, max=39726\n",
      "2025-04-30 13:02:07 [INFO]   Expected vocabulary size (n_tokens): 39727\n",
      "2025-04-30 13:02:07 [INFO]   Token IDs are within the expected range.\n",
      "2025-04-30 13:02:07 [INFO] Loaded 9539 training samples, 10000 validation samples.\n",
      "2025-04-30 13:02:07 [INFO] Loading test dataloader...\n",
      "2025-04-30 13:02:07 [INFO] Loading full dataset arrays from: /changed/final_data/arrays/48_0_20-arrays.npz\n",
      "2025-04-30 13:02:09 [INFO]  Loaded data shapes: X=(24424, 10000, 2), Y=(24424,), Paths=(24424,)\n",
      "2025-04-30 13:02:09 [INFO] Loading token map from: /changed/final_data/dictionaries/48_0_20-token2index.npy\n",
      "2025-04-30 13:02:09 [INFO]  Token map loaded. Vocabulary size (n_tokens): 39727\n",
      "2025-04-30 13:02:09 [INFO] Loaded test set: 4885 samples based on /changed/final_data/splits/0-48-test.csv\n",
      "2025-04-30 13:02:10 [INFO] üîç Initial Token ID range in loaded data: min=0, max=39726\n",
      "2025-04-30 13:02:10 [INFO]   Expected vocabulary size (n_tokens): 39727\n",
      "2025-04-30 13:02:10 [INFO]   Token IDs are within the expected range.\n"
     ]
    }
   ],
   "source": [
    "logger.info(\"Loading token map...\")\n",
    "\n",
    "token2index = np.load(token_map_path, allow_pickle=True).item()\n",
    "n_tokens = len(token2index)\n",
    "logger.info(f\"Vocabulary size (n_tokens): {n_tokens}\")\n",
    "if n_tokens == 0: raise ValueError(\"Token map is empty.\")\n",
    "\n",
    "\n",
    "logger.info(\"Loading train/validation dataloaders...\")\n",
    "train_loader, valid_loader = get_dataloaders(\n",
    "    array_path=array_path, token_map_path=token_map_path,\n",
    "    train_split_path=train_split_path, valid_split_path=valid_split_path,\n",
    "    validation=True, t_hours=T_HOURS, dt=DT, dynamic=DYNAMIC,\n",
    "    batch_size=BATCH_SIZE, logger=logger, shuffle=True\n",
    ")\n",
    "logger.info(f'Loaded {len(train_loader.dataset)} training samples, {len(valid_loader.dataset)} validation samples.')\n",
    "\n",
    "\n",
    "logger.info(\"Loading test dataloader...\")\n",
    "test_loader, _ = get_dataloaders(\n",
    "    array_path=array_path, token_map_path=token_map_path,\n",
    "    test_split_path=test_split_path, # Provide test split path\n",
    "    validation=False, # Load test set\n",
    "    t_hours=T_HOURS, dt=DT, dynamic=DYNAMIC,\n",
    "    batch_size=BATCH_SIZE, logger=logger, shuffle=False # No shuffle for test\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c373fb97",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-30 13:02:10 [INFO] Initializing model: Mortality\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing model of type Mortality...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-30 13:02:10 [INFO] # trainable parameters: 1,572,097\n"
     ]
    }
   ],
   "source": [
    "# ## 5. Initialize Model, Optimizer, Loss\n",
    "\n",
    "logger.info(f\"Initializing model: {MODEL_TYPE}\")\n",
    "\n",
    "# Ensure using models.py that doesn't have ReLU after embedder if testing that fix\n",
    "model = init_model(\n",
    "    model_type=MODEL_TYPE, n_tokens=n_tokens, latent_dim=LATENT_DIM,\n",
    "    hidden_dim=HIDDEN_DIM, p_dropout=P_DROPOUT, dt=DT,\n",
    "    weighted=WEIGHTED, # Pass the flag\n",
    "    dynamic=DYNAMIC\n",
    ")\n",
    "logger.info(f'# trainable parameters: {get_n_param(model):,}')\n",
    "model = model.to(device)\n",
    "\n",
    "\n",
    "# Optimizer and Loss\n",
    "optimizer = optim.Adam(model.parameters(), lr=LR)\n",
    "loss_f = BCE() # Use corrected version expecting logits\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9471207b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## 6. Define Evaluation Function\n",
    "\n",
    "def run_evaluation(model, loader, loss_f, device, phase='valid'):\n",
    "    \"\"\"Runs evaluation on validation or test set.\"\"\"\n",
    "    model.eval() # Set model to evaluation mode\n",
    "    epoch_loss = 0.\n",
    "    y_preds_list = []\n",
    "    y_trues_list = []\n",
    "    num_batches = len(loader)\n",
    "    storer = defaultdict(list) # Storer for this evaluation run\n",
    "\n",
    "    iterator = tqdm(enumerate(loader), total=num_batches, desc=f\"Evaluating ({phase})\", leave=False)\n",
    "\n",
    "    with torch.no_grad(): # Disable gradients\n",
    "        for i, batch in iterator:\n",
    "            try:\n",
    "                 data, y_true = batch\n",
    "            except ValueError:\n",
    "                 logger.error(f\"Unexpected batch format at eval iteration {i}. Skipping batch.\")\n",
    "                 continue\n",
    "\n",
    "            data = data.to(device)\n",
    "            y_true = y_true.to(device)\n",
    "\n",
    "            try:\n",
    "                y_pred = model(data) # Get logits\n",
    "                iter_loss = loss_f(y_pred, y_true, is_train=False, storer=storer) # Pass storer\n",
    "\n",
    "                if not torch.isfinite(iter_loss):\n",
    "                     logger.warning(f\"NaN or Inf loss detected during {phase} iteration {i+1}.\")\n",
    "                     epoch_loss += float('nan')\n",
    "                else:\n",
    "                     epoch_loss += iter_loss.item()\n",
    "\n",
    "                # Store predictions (logits) and true labels\n",
    "                y_preds_list.append(y_pred.detach().cpu())\n",
    "                y_trues_list.append(y_true.detach().cpu())\n",
    "\n",
    "                iterator.set_postfix(loss=f\"{iter_loss.item():.4f}\" if torch.isfinite(iter_loss) else \"nan\")\n",
    "\n",
    "            except Exception as e:\n",
    "                 logger.error(f\"Error during {phase} iteration {i+1}: {e}\", exc_info=True)\n",
    "\n",
    "    avg_loss = np.nanmean([l for l in storer.get(f'{phase}_loss', []) if l is not None]) if storer.get(f'{phase}_loss') else float('nan')\n",
    "    if not np.isfinite(avg_loss) and num_batches > 0: avg_loss = epoch_loss / num_batches # Fallback calculation\n",
    "\n",
    "    # --- Compute Metrics ---\n",
    "    final_metrics = {'loss': avg_loss, 'auroc': None} # Default metrics\n",
    "    try:\n",
    "        y_preds_all = torch.cat(y_preds_list, dim=0)\n",
    "        y_trues_all = torch.cat(y_trues_list, dim=0)\n",
    "\n",
    "        # Convert to numpy for sklearn\n",
    "        y_pred_np = array(y_preds_all)\n",
    "        y_true_np = array(y_trues_all)\n",
    "\n",
    "        # Handle dynamic output shapes (take last time step)\n",
    "        if y_pred_np.ndim == 2: y_pred_np = y_pred_np[:, -1]\n",
    "        if y_true_np.ndim == 2: y_true_np = y_true_np[:, -1]\n",
    "\n",
    "        # Apply sigmoid to get probabilities for AUROC\n",
    "        probs = 1 / (1 + np.exp(-y_pred_np))\n",
    "\n",
    "        if np.isnan(probs).any() or np.isnan(y_true_np).any():\n",
    "             logger.warning(f\"NaN values detected in {phase} predictions or labels before metric calculation.\")\n",
    "        else:\n",
    "             if len(np.unique(y_true_np)) > 1:\n",
    "                  final_metrics['auroc'] = roc_auc_score(y_true_np, probs)\n",
    "             else:\n",
    "                  logger.warning(f\"Only one class present in true labels during {phase}. AUROC is not defined.\")\n",
    "\n",
    "    except Exception as e:\n",
    "         logger.error(f\"Error computing {phase} metrics: {e}\")\n",
    "\n",
    "    return final_metrics, y_preds_all, y_trues_all # Return preds/trues as well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f47b8c40",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/changed/.conda/envs/mimic3_denis_project/lib/python3.11/site-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\n",
      "2025-04-30 13:02:44 [INFO] --- Starting Full Training & Validation Loop ---\n",
      "Epoch 1/150:   0%|          | 0/11250 [00:00<?, ?batch/s]              "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/150:   0%|          | 5/11250 [00:17<10:40:50,  3.42s/batch, loss=0.6705, lr=1.0e-04]\n",
      "2025-04-30 13:03:02 [INFO] Finished training loop after 0.3 minutes. Best Valid AUROC: -inf\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 65\u001b[39m\n\u001b[32m     62\u001b[39m optimizer.zero_grad()\n\u001b[32m     64\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m65\u001b[39m     y_pred = \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     66\u001b[39m     iter_loss = loss_f(y_pred, y_true, is_train=\u001b[38;5;28;01mTrue\u001b[39;00m, storer=epoch_storer)\n\u001b[32m     68\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m torch.isfinite(iter_loss):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.conda/envs/mimic3_denis_project/lib/python3.11/site-packages/torch/nn/modules/module.py:1739\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1737\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1738\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1739\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.conda/envs/mimic3_denis_project/lib/python3.11/site-packages/torch/nn/modules/module.py:1750\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1745\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1746\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1747\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1748\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1749\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1750\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1752\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1753\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/changed/models/models.py:116\u001b[39m, in \u001b[36mModel.forward\u001b[39m\u001b[34m(self, input)\u001b[39m\n\u001b[32m    107\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[32m    108\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    109\u001b[39m \u001b[33;03m    Forward pass of model.\u001b[39;00m\n\u001b[32m    110\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    114\u001b[39m \u001b[33;03m        Batch of data. Shape (batch_size, 10000, 2)\u001b[39;00m\n\u001b[32m    115\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m116\u001b[39m     emb = \u001b[38;5;28mself\u001b[39m.dropout(F.relu(\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43membedder\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m))\n\u001b[32m    117\u001b[39m     all_hidden, (final_hidden, _) = \u001b[38;5;28mself\u001b[39m.lstm(emb)\n\u001b[32m    118\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.dynamic:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.conda/envs/mimic3_denis_project/lib/python3.11/site-packages/torch/nn/modules/module.py:1739\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1737\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1738\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1739\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.conda/envs/mimic3_denis_project/lib/python3.11/site-packages/torch/nn/modules/module.py:1750\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1745\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1746\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1747\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1748\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1749\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1750\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1752\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1753\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/changed/models/embedders.py:76\u001b[39m, in \u001b[36mEmbedder.forward\u001b[39m\u001b[34m(self, X)\u001b[39m\n\u001b[32m     73\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     74\u001b[39m         X_t = t_idx * embedded\n\u001b[32m---> \u001b[39m\u001b[32m76\u001b[39m     X_t_avg = \u001b[43mX_t\u001b[49m\u001b[43m.\u001b[49m\u001b[43msum\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdim\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkeepdim\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m / (counts + \u001b[32m1e-6\u001b[39m)\n\u001b[32m     77\u001b[39m     output += [X_t_avg]\n\u001b[32m     79\u001b[39m output = torch.cat(output, dim=\u001b[32m1\u001b[39m)\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau, StepLR, CosineAnnealingLR\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from timeit import default_timer\n",
    "import logging\n",
    "import os\n",
    "from collections import defaultdict\n",
    "\n",
    "\n",
    "# --- Scheduler and Optimizer Setup (from your code) ---\n",
    "SCHEDULER_TYPE = 'ReduceLROnPlateau'\n",
    "SCHEDULER_FACTOR = 0.5 # Factor by which the LR is reduced (new_lr = lr * factor)\n",
    "SCHEDULER_PATIENCE = 2 # Number of epochs with no improvement after which LR is reduced\n",
    "SCHEDULER_MODE = 'max' # 'max' for AUROC, 'min' for loss\n",
    "SCHEDULER_MIN_LR = 1e-6 # Minimum learning rate\n",
    "\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=LR)\n",
    "scheduler = None\n",
    "if SCHEDULER_TYPE == 'ReduceLROnPlateau':\n",
    "    scheduler = ReduceLROnPlateau(optimizer,\n",
    "                                  mode=SCHEDULER_MODE,\n",
    "                                  factor=SCHEDULER_FACTOR,\n",
    "                                  patience=SCHEDULER_PATIENCE,\n",
    "                                  min_lr=SCHEDULER_MIN_LR,\n",
    "                                  verbose=True)\n",
    "# Add other scheduler types if needed...\n",
    "\n",
    "logger.info(\"--- Starting Full Training & Validation Loop ---\")\n",
    "\n",
    "start_time = default_timer()\n",
    "max_v_auroc = -np.inf\n",
    "early_stopping_counter = 0\n",
    "patience = float('inf') if EARLY_STOPPING_PATIENCE is None or EARLY_STOPPING_PATIENCE <= 0 else EARLY_STOPPING_PATIENCE\n",
    "\n",
    "# --- Calculate Total Batches and Initialize Overall Progress Bar ---\n",
    "num_train_batches_per_epoch = len(train_loader)\n",
    "total_batches = EPOCHS * num_train_batches_per_epoch\n",
    "overall_progress_bar = tqdm(total=total_batches, desc=\"Overall Training Progress\", unit=\"batch\")\n",
    "# -------------------------------------------------------------------\n",
    "\n",
    "try: # Use try...finally to ensure the progress bar is closed\n",
    "    for epoch in range(EPOCHS):\n",
    "        model.train() # Set model to training mode\n",
    "        epoch_train_loss = 0.\n",
    "        epoch_storer = defaultdict(list) # Storer for metrics logged by loss_f\n",
    "        nan_detected_in_epoch = False\n",
    "\n",
    "        # --- Update Progress Bar Description for the Current Epoch ---\n",
    "        overall_progress_bar.set_description(f\"Epoch {epoch+1}/{EPOCHS}\")\n",
    "        # -------------------------------------------------------------\n",
    "\n",
    "        # --- Training Batch Loop (Iterate directly, NO inner tqdm) ---\n",
    "        for i, batch in enumerate(train_loader):\n",
    "            try: data, y_true = batch\n",
    "            except ValueError: logger.error(f\"Train batch format error iter {i}. Skipping.\"); continue\n",
    "\n",
    "            data = data.to(device)\n",
    "            y_true = y_true.to(device)\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            try:\n",
    "                y_pred = model(data)\n",
    "                iter_loss = loss_f(y_pred, y_true, is_train=True, storer=epoch_storer)\n",
    "\n",
    "                if not torch.isfinite(iter_loss):\n",
    "                    logger.error(f\"NaN or Inf loss detected during training iteration {i+1} in Epoch {epoch+1}. Stopping epoch.\")\n",
    "                    nan_detected_in_epoch = True; break\n",
    "\n",
    "                epoch_train_loss += iter_loss.item()\n",
    "                iter_loss.backward()\n",
    "                torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "                optimizer.step()\n",
    "\n",
    "                # --- Update Overall Progress Bar ---\n",
    "                current_lr = optimizer.param_groups[0]['lr']\n",
    "                overall_progress_bar.set_postfix(loss=f\"{iter_loss.item():.4f}\", lr=f\"{current_lr:.1e}\", refresh=True) # refresh=True might be needed\n",
    "                overall_progress_bar.update(1) # Increment the overall progress bar\n",
    "                # -----------------------------------\n",
    "\n",
    "            except Exception as e:\n",
    "                logger.error(f\"Error during training iteration {i+1} in Epoch {epoch+1}: {e}\", exc_info=True)\n",
    "                nan_detected_in_epoch = True; break # Stop epoch on error\n",
    "\n",
    "\n",
    "\n",
    "        # If epoch completed normally, calculate average loss\n",
    "        avg_train_loss = epoch_train_loss / num_train_batches_per_epoch if num_train_batches_per_epoch > 0 else float('nan')\n",
    "        epoch_storer['train_loss'] = [avg_train_loss]\n",
    "\n",
    "        # --- Validation Step ---\n",
    "        val_metrics, _, _ = run_evaluation(model, valid_loader, loss_f, device, phase='valid')\n",
    "        val_loss = val_metrics.get('loss', float('nan'))\n",
    "        val_auroc = val_metrics.get('auroc', None)\n",
    "        epoch_storer['valid_loss'] = [val_loss]\n",
    "        if val_auroc is not None:\n",
    "            epoch_storer['auroc'] = [val_auroc]\n",
    "\n",
    "\n",
    "        # --- Logging ---\n",
    "        current_lr = optimizer.param_groups[0]['lr']\n",
    "        log_msg = f\"Epoch {epoch+1} End: Train Loss={avg_train_loss:.4f}, Valid Loss={val_loss:.4f}\"\n",
    "        if val_auroc is not None: log_msg += f\", Valid AUROC={val_auroc:.4f}\"\n",
    "        else: log_msg += \", Valid AUROC=N/A\"\n",
    "        logger.info(log_msg)\n",
    "        if losses_logger: losses_logger.log(epoch, epoch_storer)\n",
    "\n",
    "        # --- Scheduler Step (End of Epoch) ---\n",
    "        if scheduler:\n",
    "            if isinstance(scheduler, ReduceLROnPlateau):\n",
    "                 metric_to_monitor = val_auroc if val_auroc is not None else (-np.inf if SCHEDULER_MODE == 'max' else np.inf)\n",
    "                 scheduler.step(metric_to_monitor)\n",
    "            else:\n",
    "                 scheduler.step()\n",
    "\n",
    "\n",
    "        # --- Checkpointing & Early Stopping ---\n",
    "        improved = False\n",
    "        if val_auroc is not None and np.isfinite(val_auroc):\n",
    "            if val_auroc > max_v_auroc:\n",
    "                max_v_auroc = val_auroc\n",
    "                # Save model and metadata... (Your existing code)\n",
    "                model_save_path = os.path.join(model_dir, 'model.pt')\n",
    "                torch.save(model.state_dict(), model_save_path)\n",
    "                run_metadata = { # Collect metadata for this run\n",
    "                     't_hours': T_HOURS, 'n_bins': N_BINS, 'seed': SEED, 'lr': LR,\n",
    "                     'epochs': EPOCHS, 'batch_size': BATCH_SIZE, 'latent_dim': LATENT_DIM,\n",
    "                     'hidden_dim': HIDDEN_DIM, 'p_dropout': P_DROPOUT, 'dt': DT,\n",
    "                     'weighted': WEIGHTED, 'dynamic': DYNAMIC, 'n_tokens': n_tokens,\n",
    "                     'model_type': MODEL_TYPE,\n",
    "                     'best_epoch': epoch + 1,\n",
    "                     'best_auroc': max_v_auroc\n",
    "                 }\n",
    "                save_metadata(run_metadata, model_dir, filename='meta.json')\n",
    "                early_stopping_counter = 0\n",
    "                improved = True\n",
    "\n",
    "        if not improved:\n",
    "            early_stopping_counter += 1\n",
    "            # Log lack of improvement... (Your existing code)\n",
    "            if val_auroc is not None:\n",
    "                 logger.info(f\"  Validation AUROC did not improve from {max_v_auroc:.4f}. Early stopping counter: {early_stopping_counter}/{patience}\")\n",
    "            else:\n",
    "                 logger.info(f\"  Validation AUROC is N/A. Not checking improvement. Early stopping counter: {early_stopping_counter}/{patience}\")\n",
    "\n",
    "\n",
    "        if early_stopping_counter >= patience:\n",
    "            logger.info(f\"Early stopping triggered after {patience} epochs without improvement.\")\n",
    "            break # Break the main epoch loop\n",
    "\n",
    "finally: # Ensure the progress bar is closed even if errors occur\n",
    "    overall_progress_bar.close()\n",
    "    # --- End of Training Loop ---\n",
    "    delta_time = (default_timer() - start_time) / 60\n",
    "    logger.info(f'Finished training loop after {delta_time:.1f} minutes. Best Valid AUROC: {max_v_auroc:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1040f2e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-22 18:14:14 [INFO] --- Starting Final Test Set Evaluation ---\n",
      "2025-04-22 18:14:14 [INFO] Loading best model from /changed/results/MortalityLSTM_t48_lr0.0001_z32_h256_p0.0_wFalse_dTrue_seed0...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing model of type Mortality...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-22 18:14:15 [INFO] Best model loaded successfully.\n",
      "2025-04-22 18:14:15 [INFO] --- Test Set Results ---                          \n",
      "2025-04-22 18:14:15 [INFO] ‚úÖ Test Loss : 0.3734\n",
      "2025-04-22 18:14:15 [INFO] ‚úÖ Test AUROC: 0.6725\n"
     ]
    }
   ],
   "source": [
    "# ## 8. Final Test Set Evaluation\n",
    "\n",
    "logger.info(\"--- Starting Final Test Set Evaluation ---\")\n",
    "\n",
    "# Load the best model saved during training\n",
    "logger.info(f\"Loading best model from {model_dir}...\")\n",
    "try:\n",
    "    # Re-initialize model architecture\n",
    "    best_model = init_model(\n",
    "        model_type=MODEL_TYPE, n_tokens=n_tokens, latent_dim=LATENT_DIM,\n",
    "        hidden_dim=HIDDEN_DIM, p_dropout=P_DROPOUT, dt=DT,\n",
    "        weighted=WEIGHTED, dynamic=DYNAMIC\n",
    "    )\n",
    "    # Load state dict\n",
    "    model_path = os.path.join(model_dir, 'model.pt')\n",
    "    if not os.path.exists(model_path): raise FileNotFoundError(\"Best model file not found.\")\n",
    "    best_model.load_state_dict(torch.load(model_path, map_location=device))\n",
    "    best_model.to(device)\n",
    "    best_model.eval()\n",
    "    logger.info(\"Best model loaded successfully.\")\n",
    "except Exception as e:\n",
    "     logger.error(f\"Error loading best model for testing: {e}\"); raise\n",
    "\n",
    "# Run evaluation on the test set\n",
    "test_metrics, test_preds, test_trues = run_evaluation(best_model, test_loader, loss_f, device, phase='test')\n",
    "\n",
    "test_loss = test_metrics['loss']\n",
    "test_auroc = test_metrics['auroc']\n",
    "\n",
    "logger.info(f\"--- Test Set Results ---\")\n",
    "logger.info(f\"‚úÖ Test Loss : {test_loss:.4f}\" if np.isfinite(test_loss) else \"Test Loss : nan\")\n",
    "logger.info(f\"‚úÖ Test AUROC: {test_auroc:.4f}\" if test_auroc is not None and np.isfinite(test_auroc) else \"Test AUROC: N/A\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d12faa6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-22 18:14:15 [INFO] Test predictions saved to /changed/results/MortalityLSTM_t48_lr0.0001_z32_h256_p0.0_wFalse_dTrue_seed0/test_predictions.npz\n",
      "2025-04-22 18:14:15 [INFO] Appending results to summary file: /changed/results/summary_results.csv\n"
     ]
    }
   ],
   "source": [
    "# Save test predictions and labels\n",
    "test_results_path = os.path.join(model_dir, 'test_predictions.npz')\n",
    "\n",
    "np.savez(test_results_path,\n",
    "            predictions=test_preds.numpy(), # Convert tensors to numpy\n",
    "            labels=test_trues.numpy())\n",
    "logger.info(f\"Test predictions saved to {test_results_path}\")\n",
    "\n",
    "\n",
    "# Append to overall summary CSV\n",
    "summary_file_path = os.path.join(RESULTS_DIR, 'summary_results.csv')\n",
    "logger.info(f\"Appending results to summary file: {summary_file_path}\")\n",
    "\n",
    "fieldnames = [\n",
    "    'timestamp', 'model_run_name', 't_hours', 'seed', 'n_bins', 'lr',\n",
    "    'batch_size', 'latent_dim', 'hidden_dim', 'p_dropout', 'weighted', 'dynamic',\n",
    "    'max_epochs', 'best_valid_auroc', 'test_loss', 'test_auroc', 'n_tokens', 'n_params',\n",
    "    'model_dir', 'predictions_path'\n",
    "]\n",
    "n_params = get_n_param(best_model)\n",
    "\n",
    "result_data = {\n",
    "    'timestamp': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),\n",
    "    'model_run_name': model_run_name,\n",
    "    't_hours': T_HOURS, 'seed': SEED, 'n_bins': N_BINS, 'lr': LR,\n",
    "    'batch_size': BATCH_SIZE, 'latent_dim': LATENT_DIM, 'hidden_dim': HIDDEN_DIM,\n",
    "    'p_dropout': P_DROPOUT, 'weighted': WEIGHTED, 'dynamic': DYNAMIC,\n",
    "    'max_epochs': EPOCHS, # Or store actual epochs run before early stopping\n",
    "    'best_valid_auroc': f\"{max_v_auroc:.4f}\" if np.isfinite(max_v_auroc) else \"-inf\",\n",
    "    'test_loss': f\"{test_loss:.4f}\" if np.isfinite(test_loss) else \"nan\",\n",
    "    'test_auroc': f\"{test_auroc:.4f}\" if test_auroc is not None and np.isfinite(test_auroc) else \"N/A\",\n",
    "    'n_tokens': n_tokens, 'n_params': n_params,\n",
    "    'model_dir': model_dir,\n",
    "    'predictions_path': test_results_path if os.path.exists(test_results_path) else 'N/A'\n",
    "}\n",
    "\n",
    "\n",
    "file_exists = os.path.isfile(summary_file_path)\n",
    "with open(summary_file_path, 'a', newline='', encoding='utf-8') as csvfile:\n",
    "    writer = csv.DictWriter(csvfile, fieldnames=fieldnames, extrasaction='ignore') # Ignore extra keys if any\n",
    "    if not file_exists or os.path.getsize(summary_file_path) == 0:\n",
    "        writer.writeheader()\n",
    "    writer.writerow(result_data)\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
